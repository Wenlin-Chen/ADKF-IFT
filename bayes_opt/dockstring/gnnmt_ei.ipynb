{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c583b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pyprojroot import here as project_root\n",
    "\n",
    "sys.path.insert(0, str(project_root()))\n",
    "\n",
    "from fs_mol.data.multitask import get_multitask_inference_batcher\n",
    "from fs_mol.utils.torch_utils import torchify\n",
    "\n",
    "from fs_mol.models.gnn_multitask import GNNMultitaskModel\n",
    "\n",
    "from bayes_opt.bo_utils import load_dockstring_dataset, run_gp_ei_bo, min_so_far, task_to_batches\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b7123ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = load_dockstring_dataset(\"dockstring-dataset-subsampled.csv\", \"../../fs_mol/preprocessing/utils/helper_files/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ac1070b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batcher = get_multitask_inference_batcher(max_num_graphs=30, device=device)\n",
    "gnnmt_batches = torchify(\n",
    "    task_to_batches(task, batcher), \n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a342b4f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GNNMultitaskModel(\n",
       "  (criterion): BCEWithLogitsLoss()\n",
       "  (graph_feature_extractor): GraphFeatureExtractor(\n",
       "    (init_node_proj): Linear(in_features=32, out_features=128, bias=False)\n",
       "    (gnn): GNN(\n",
       "      (gnn_blocks): ModuleList(\n",
       "        (0): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (6): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (7): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (8): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (9): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (readout): CombinedGraphReadout(\n",
       "      (_weighted_mean_pooler): MultiHeadWeightedGraphReadout(\n",
       "        (_scoring_module): MLP(\n",
       "          (_layers): Sequential(\n",
       "            (0): Linear(in_features=1408, out_features=768, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=768, out_features=12, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (_transformation_mlp): MLP(\n",
       "          (_layers): Sequential(\n",
       "            (0): Linear(in_features=1408, out_features=768, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (_combination_layer): Linear(in_features=768, out_features=512, bias=False)\n",
       "      )\n",
       "      (_weighted_sum_pooler): MultiHeadWeightedGraphReadout(\n",
       "        (_scoring_module): MLP(\n",
       "          (_layers): Sequential(\n",
       "            (0): Linear(in_features=1408, out_features=768, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=768, out_features=12, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (_transformation_mlp): MLP(\n",
       "          (_layers): Sequential(\n",
       "            (0): Linear(in_features=1408, out_features=768, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (_combination_layer): Linear(in_features=768, out_features=512, bias=False)\n",
       "      )\n",
       "      (_max_pooler): UnweightedGraphReadout(\n",
       "        (_combination_layer): Linear(in_features=1408, out_features=512, bias=False)\n",
       "      )\n",
       "      (_combination_layer): Linear(in_features=1536, out_features=512, bias=False)\n",
       "    )\n",
       "  )\n",
       "  (tail_mlp): MLP(\n",
       "    (_layers): Sequential(\n",
       "      (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=512, out_features=4938, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_weights_file = \"../../../fs-mol-checkpoints/multitask_best_model.pt\"\n",
    "\n",
    "gnnmt_model = GNNMultitaskModel.build_from_model_file(\n",
    "    model_weights_file,\n",
    "    device=device\n",
    ").to(device)\n",
    "\n",
    "gnnmt_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5206bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "representations = []\n",
    "\n",
    "for features in gnnmt_batches:\n",
    "    with torch.no_grad():\n",
    "        representation = gnnmt_model.graph_feature_extractor(features)\n",
    "    representations.append(representation)\n",
    "    \n",
    "del gnnmt_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34d6a02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = task.samples\n",
    "\n",
    "x_all = torch.cat(representations, dim=0)\n",
    "y_all = torch.FloatTensor([float(x.numeric_label) for x in dataset]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7406af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_init_points = 16\n",
    "query_batch_size = 1\n",
    "num_bo_iters = 20\n",
    "kernel_type = \"matern\"\n",
    "init_from = 1600\n",
    "noise_init = 0.01\n",
    "noise_prior = True\n",
    "\n",
    "num_repeats = 20\n",
    "\n",
    "bo_records = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fc4efa9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 20/20 [27:30<00:00, 82.55s/it]\n"
     ]
    }
   ],
   "source": [
    "for repeat in tqdm(range(num_repeats)):\n",
    "    bo_record = run_gp_ei_bo(dataset, x_all, y_all, num_init_points, query_batch_size, num_bo_iters, kernel_type, device, init_from, noise_init, noise_prior)\n",
    "    bo_records.append(min_so_far(bo_record))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4752fcaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Top-1 ESR2')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_axis = np.arange(query_batch_size*num_bo_iters+1)\n",
    "\n",
    "bo_records = np.array([[y_all[i].item() for i in bo_record] for bo_record in bo_records])\n",
    "bo_records_mean = bo_records.mean(axis=0)\n",
    "bo_records_std = bo_records.std(axis=0)\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "\n",
    "plt.plot(x_axis, bo_records_mean)\n",
    "plt.fill_between(x_axis, bo_records_mean-bo_records_std, bo_records_mean+bo_records_std, alpha=0.4)\n",
    "\n",
    "plt.xlabel(\"Number of molecules queried\")\n",
    "plt.ylabel(\"Top-1 ESR2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac81272a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"outputs/gnnmt_bo_records.pkl\", \"wb\") as output_file:\n",
    "    pickle.dump(bo_records, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2373d762",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
