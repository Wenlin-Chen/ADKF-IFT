{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c583b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pyprojroot import here as project_root\n",
    "\n",
    "sys.path.insert(0, str(project_root()))\n",
    "\n",
    "from fs_mol.data.cnp import get_cnp_batcher\n",
    "from fs_mol.utils.torch_utils import torchify\n",
    "\n",
    "from bayes_opt.bo_utils import load_dockstring_dataset, run_gp_ei_bo, min_so_far, task_to_batches, CNPModelFeatureExtractor\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b7123ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = load_dockstring_dataset(\"dockstring-dataset-subsampled.csv\", \"../../fs_mol/preprocessing/utils/helper_files/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ac1070b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batcher = get_cnp_batcher(max_num_graphs=100)\n",
    "cnp_batches = torchify(\n",
    "    task_to_batches(task, batcher), \n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a342b4f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNPModelFeatureExtractor(\n",
       "  (graph_feature_extractor): GraphFeatureExtractor(\n",
       "    (init_node_proj): Linear(in_features=32, out_features=128, bias=False)\n",
       "    (gnn): GNN(\n",
       "      (gnn_blocks): ModuleList(\n",
       "        (0): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (6): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (7): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (8): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (9): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (readout): CombinedGraphReadout(\n",
       "      (_weighted_mean_pooler): MultiHeadWeightedGraphReadout(\n",
       "        (_scoring_module): MLP(\n",
       "          (_layers): Sequential(\n",
       "            (0): Linear(in_features=1408, out_features=768, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=768, out_features=12, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (_transformation_mlp): MLP(\n",
       "          (_layers): Sequential(\n",
       "            (0): Linear(in_features=1408, out_features=768, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (_combination_layer): Linear(in_features=768, out_features=512, bias=False)\n",
       "      )\n",
       "      (_weighted_sum_pooler): MultiHeadWeightedGraphReadout(\n",
       "        (_scoring_module): MLP(\n",
       "          (_layers): Sequential(\n",
       "            (0): Linear(in_features=1408, out_features=768, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=768, out_features=12, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (_transformation_mlp): MLP(\n",
       "          (_layers): Sequential(\n",
       "            (0): Linear(in_features=1408, out_features=768, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (_combination_layer): Linear(in_features=768, out_features=512, bias=False)\n",
       "      )\n",
       "      (_max_pooler): UnweightedGraphReadout(\n",
       "        (_combination_layer): Linear(in_features=1408, out_features=512, bias=False)\n",
       "      )\n",
       "      (_combination_layer): Linear(in_features=1536, out_features=512, bias=False)\n",
       "    )\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=2560, out_features=1024, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  )\n",
       "  (encoder_label_fc): Sequential(\n",
       "    (0): Linear(in_features=1, out_features=64, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "  )\n",
       "  (encoder_final_fc): Sequential(\n",
       "    (0): Linear(in_features=576, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=512, out_features=512, bias=True)\n",
       "  )\n",
       "  (decoder_fc): Sequential(\n",
       "    (0): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (7): ReLU()\n",
       "    (8): Linear(in_features=256, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_weights_file = \"../../outputs/FSMol_CNPModel_gnn+ecfp+fc_2022-04-11_16-46-27/best_validation.pt\" #2048\n",
    "\n",
    "cnp_model = CNPModelFeatureExtractor.build_from_model_file(\n",
    "    model_weights_file,\n",
    "    device=device\n",
    ").to(device)\n",
    "\n",
    "cnp_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5206bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "representations = []\n",
    "\n",
    "for features in cnp_batches:\n",
    "    representation = cnp_model.get_representation(features)\n",
    "    representations.append(representation)\n",
    "    \n",
    "del cnp_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34d6a02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = task.samples\n",
    "\n",
    "x_all = torch.cat(representations, dim=0)\n",
    "y_all = torch.FloatTensor([float(x.numeric_label) for x in dataset]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7406af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_init_points = 16\n",
    "query_batch_size = 1\n",
    "num_bo_iters = 20\n",
    "kernel_type = \"matern\"\n",
    "init_from = 1600\n",
    "noise_init = 0.01\n",
    "noise_prior = True\n",
    "\n",
    "num_repeats = 20\n",
    "\n",
    "bo_records = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fc4efa9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 20/20 [26:21<00:00, 79.07s/it]\n"
     ]
    }
   ],
   "source": [
    "for repeat in tqdm(range(num_repeats)):\n",
    "    bo_record = run_gp_ei_bo(dataset, x_all, y_all, num_init_points, query_batch_size, num_bo_iters, kernel_type, device, init_from, noise_init, noise_prior)\n",
    "    bo_records.append(min_so_far(bo_record))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4752fcaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Top-1 ESR2')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_axis = np.arange(query_batch_size*num_bo_iters+1)\n",
    "\n",
    "bo_records = np.array([[y_all[i].item() for i in bo_record] for bo_record in bo_records])\n",
    "bo_records_mean = bo_records.mean(axis=0)\n",
    "bo_records_std = bo_records.std(axis=0)\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "\n",
    "plt.plot(x_axis, bo_records_mean)\n",
    "plt.fill_between(x_axis, bo_records_mean-bo_records_std, bo_records_mean+bo_records_std, alpha=0.4)\n",
    "\n",
    "plt.xlabel(\"Number of molecules queried\")\n",
    "plt.ylabel(\"Top-1 ESR2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac81272a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"outputs/cnp_bo_records.pkl\", \"wb\") as output_file:\n",
    "    pickle.dump(bo_records, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2373d762",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
