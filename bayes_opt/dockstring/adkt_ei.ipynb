{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c583b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pyprojroot import here as project_root\n",
    "\n",
    "sys.path.insert(0, str(project_root()))\n",
    "\n",
    "from fs_mol.data.dkt import get_dkt_batcher\n",
    "from fs_mol.utils.torch_utils import torchify\n",
    "\n",
    "from bayes_opt.bo_utils import load_dockstring_dataset, run_gp_ei_bo, min_so_far, task_to_batches, ADKTModelFeatureExtractor\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b7123ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = load_dockstring_dataset(\"dockstring-dataset-subsampled.csv\", \"../../fs_mol/preprocessing/utils/helper_files/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ac1070b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batcher = get_dkt_batcher(max_num_graphs=100)\n",
    "dkt_batches = torchify(\n",
    "    task_to_batches(task, batcher), \n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a342b4f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ADKTModelFeatureExtractor(\n",
       "  (graph_feature_extractor): GraphFeatureExtractor(\n",
       "    (init_node_proj): Linear(in_features=32, out_features=128, bias=False)\n",
       "    (gnn): GNN(\n",
       "      (gnn_blocks): ModuleList(\n",
       "        (0): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (6): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (7): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (8): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (9): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (readout): CombinedGraphReadout(\n",
       "      (_weighted_mean_pooler): MultiHeadWeightedGraphReadout(\n",
       "        (_scoring_module): MLP(\n",
       "          (_layers): Sequential(\n",
       "            (0): Linear(in_features=1408, out_features=768, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=768, out_features=12, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (_transformation_mlp): MLP(\n",
       "          (_layers): Sequential(\n",
       "            (0): Linear(in_features=1408, out_features=768, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (_combination_layer): Linear(in_features=768, out_features=512, bias=False)\n",
       "      )\n",
       "      (_weighted_sum_pooler): MultiHeadWeightedGraphReadout(\n",
       "        (_scoring_module): MLP(\n",
       "          (_layers): Sequential(\n",
       "            (0): Linear(in_features=1408, out_features=768, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=768, out_features=12, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (_transformation_mlp): MLP(\n",
       "          (_layers): Sequential(\n",
       "            (0): Linear(in_features=1408, out_features=768, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (_combination_layer): Linear(in_features=768, out_features=512, bias=False)\n",
       "      )\n",
       "      (_max_pooler): UnweightedGraphReadout(\n",
       "        (_combination_layer): Linear(in_features=1408, out_features=512, bias=False)\n",
       "      )\n",
       "      (_combination_layer): Linear(in_features=1536, out_features=512, bias=False)\n",
       "    )\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=2560, out_features=1024, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  )\n",
       "  (gp_likelihood): GaussianLikelihood(\n",
       "    (noise_covar): HomoskedasticNoise(\n",
       "      (noise_prior): LogNormalPrior()\n",
       "      (raw_noise_constraint): GreaterThan(1.000E-04)\n",
       "    )\n",
       "  )\n",
       "  (gp_model): ExactGPLayer(\n",
       "    (likelihood): GaussianLikelihood(\n",
       "      (noise_covar): HomoskedasticNoise(\n",
       "        (noise_prior): LogNormalPrior()\n",
       "        (raw_noise_constraint): GreaterThan(1.000E-04)\n",
       "      )\n",
       "    )\n",
       "    (mean_module): ZeroMean()\n",
       "    (covar_module): ScaleKernel(\n",
       "      (base_kernel): MaternKernel(\n",
       "        (raw_lengthscale_constraint): Positive()\n",
       "      )\n",
       "      (raw_outputscale_constraint): Positive()\n",
       "    )\n",
       "  )\n",
       "  (mll): ExactMarginalLogLikelihood(\n",
       "    (likelihood): GaussianLikelihood(\n",
       "      (noise_covar): HomoskedasticNoise(\n",
       "        (noise_prior): LogNormalPrior()\n",
       "        (raw_noise_constraint): GreaterThan(1.000E-04)\n",
       "      )\n",
       "    )\n",
       "    (model): ExactGPLayer(\n",
       "      (likelihood): GaussianLikelihood(\n",
       "        (noise_covar): HomoskedasticNoise(\n",
       "          (noise_prior): LogNormalPrior()\n",
       "          (raw_noise_constraint): GreaterThan(1.000E-04)\n",
       "        )\n",
       "      )\n",
       "      (mean_module): ZeroMean()\n",
       "      (covar_module): ScaleKernel(\n",
       "        (base_kernel): MaternKernel(\n",
       "          (raw_lengthscale_constraint): Positive()\n",
       "        )\n",
       "        (raw_outputscale_constraint): Positive()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_weights_file = \"../../outputs/FSMol_ADKTModel_gnn+ecfp+fc_2022-03-22_15-28-36/best_validation.pt\"\n",
    "\n",
    "adkt_model = ADKTModelFeatureExtractor.build_from_model_file(\n",
    "    model_weights_file,\n",
    "    device=device\n",
    ").to(device)\n",
    "\n",
    "adkt_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5206bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "representations = []\n",
    "\n",
    "for features in dkt_batches:\n",
    "    representation = adkt_model.get_representation(features)\n",
    "    representations.append(representation)\n",
    "    \n",
    "del adkt_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34d6a02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = task.samples\n",
    "\n",
    "x_all = torch.cat(representations, dim=0)\n",
    "y_all = torch.FloatTensor([float(x.numeric_label) for x in dataset]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7406af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_init_points = 16\n",
    "query_batch_size = 1\n",
    "num_bo_iters = 20\n",
    "kernel_type = \"matern\"\n",
    "init_from = 1600\n",
    "noise_init = 0.01\n",
    "noise_prior = True\n",
    "\n",
    "num_repeats = 20\n",
    "\n",
    "bo_records = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fc4efa9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 20/20 [27:03<00:00, 81.20s/it]\n"
     ]
    }
   ],
   "source": [
    "for repeat in tqdm(range(num_repeats)):\n",
    "    bo_record = run_gp_ei_bo(dataset, x_all, y_all, num_init_points, query_batch_size, num_bo_iters, kernel_type, device, init_from, noise_init, noise_prior)\n",
    "    bo_records.append(min_so_far(bo_record))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4752fcaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f039c09de90>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_axis = np.arange(query_batch_size*num_bo_iters+1)\n",
    "\n",
    "bo_records = np.array([[y_all[i].item() for i in bo_record] for bo_record in bo_records])\n",
    "bo_records_mean = bo_records.mean(axis=0)\n",
    "bo_records_std = bo_records.std(axis=0)\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "\n",
    "plt.plot(x_axis, bo_records_mean, label=\"GP-ST\")\n",
    "plt.fill_between(x_axis, bo_records_mean-bo_records_std, bo_records_mean+bo_records_std, alpha=0.4)\n",
    "\n",
    "plt.xlabel(\"Number of molecules queried\")\n",
    "plt.ylabel(\"Top-1 ESR2\")\n",
    "#plt.ylim(3.5, 9.0)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac81272a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"outputs/adkt_bo_records.pkl\", \"wb\") as output_file:\n",
    "    pickle.dump(bo_records, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2373d762",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
