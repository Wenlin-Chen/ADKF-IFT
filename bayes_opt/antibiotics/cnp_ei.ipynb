{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c583b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pyprojroot import here as project_root\n",
    "\n",
    "sys.path.insert(0, str(project_root()))\n",
    "\n",
    "from fs_mol.data.cnp import get_cnp_batcher\n",
    "from fs_mol.utils.torch_utils import torchify\n",
    "\n",
    "from bayes_opt.bo_utils import load_antibiotics_dataset, run_gp_ei_bo, min_so_far, task_to_batches, CNPModelFeatureExtractor\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b7123ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping datapoint O=C([O-])C=CC(=O)[O-].[Fe+2], cannot featurise with current metadata.\n",
      "Skipping datapoint CC(O)CN1CCN(CC(=O)[O-])CCN(CC(=O)[O-])CCN(CC(=O)[O-])CC1.[Gd+3], cannot featurise with current metadata.\n"
     ]
    }
   ],
   "source": [
    "task = load_antibiotics_dataset(\"antibiotics-dataset.xlsx\", \"../../fs_mol/preprocessing/utils/helper_files/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ac1070b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batcher = get_cnp_batcher(max_num_graphs=100)\n",
    "cnp_batches = torchify(\n",
    "    task_to_batches(task, batcher), \n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a342b4f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNPModelFeatureExtractor(\n",
       "  (graph_feature_extractor): GraphFeatureExtractor(\n",
       "    (init_node_proj): Linear(in_features=32, out_features=128, bias=False)\n",
       "    (gnn): GNN(\n",
       "      (gnn_blocks): ModuleList(\n",
       "        (0): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (6): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (7): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (8): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (9): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (readout): CombinedGraphReadout(\n",
       "      (_weighted_mean_pooler): MultiHeadWeightedGraphReadout(\n",
       "        (_scoring_module): MLP(\n",
       "          (_layers): Sequential(\n",
       "            (0): Linear(in_features=1408, out_features=768, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=768, out_features=12, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (_transformation_mlp): MLP(\n",
       "          (_layers): Sequential(\n",
       "            (0): Linear(in_features=1408, out_features=768, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (_combination_layer): Linear(in_features=768, out_features=512, bias=False)\n",
       "      )\n",
       "      (_weighted_sum_pooler): MultiHeadWeightedGraphReadout(\n",
       "        (_scoring_module): MLP(\n",
       "          (_layers): Sequential(\n",
       "            (0): Linear(in_features=1408, out_features=768, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=768, out_features=12, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (_transformation_mlp): MLP(\n",
       "          (_layers): Sequential(\n",
       "            (0): Linear(in_features=1408, out_features=768, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (_combination_layer): Linear(in_features=768, out_features=512, bias=False)\n",
       "      )\n",
       "      (_max_pooler): UnweightedGraphReadout(\n",
       "        (_combination_layer): Linear(in_features=1408, out_features=512, bias=False)\n",
       "      )\n",
       "      (_combination_layer): Linear(in_features=1536, out_features=512, bias=False)\n",
       "    )\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=2560, out_features=1024, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  )\n",
       "  (encoder_label_fc): Sequential(\n",
       "    (0): Linear(in_features=1, out_features=64, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "  )\n",
       "  (encoder_final_fc): Sequential(\n",
       "    (0): Linear(in_features=576, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=512, out_features=512, bias=True)\n",
       "  )\n",
       "  (decoder_fc): Sequential(\n",
       "    (0): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (7): ReLU()\n",
       "    (8): Linear(in_features=256, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_weights_file = \"../../outputs/FSMol_CNPModel_gnn+ecfp+fc_2022-04-11_16-46-27/best_validation.pt\" #2048\n",
    "\n",
    "cnp_model = CNPModelFeatureExtractor.build_from_model_file(\n",
    "    model_weights_file,\n",
    "    device=device\n",
    ").to(device)\n",
    "\n",
    "cnp_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5206bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "representations = []\n",
    "\n",
    "for features in cnp_batches:\n",
    "    representation = cnp_model.get_representation(features)\n",
    "    representations.append(representation)\n",
    "    \n",
    "del cnp_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34d6a02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = task.samples\n",
    "\n",
    "x_all = torch.cat(representations, dim=0)\n",
    "y_all = torch.FloatTensor([float(x.numeric_label) for x in dataset]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7406af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_init_points = 16\n",
    "query_batch_size = 1\n",
    "num_bo_iters = 20\n",
    "kernel_type = \"matern\"\n",
    "init_from = 1600\n",
    "noise_init = 0.01\n",
    "noise_prior = True\n",
    "\n",
    "num_repeats = 20\n",
    "\n",
    "bo_records = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fc4efa9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 20/20 [26:48<00:00, 80.40s/it]\n"
     ]
    }
   ],
   "source": [
    "for repeat in tqdm(range(num_repeats)):\n",
    "    bo_record = run_gp_ei_bo(dataset, x_all, y_all, num_init_points, query_batch_size, num_bo_iters, kernel_type, device, init_from, noise_init, noise_prior)\n",
    "    bo_records.append(min_so_far(bo_record))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4752fcaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 1.5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_axis = np.arange(query_batch_size*num_bo_iters+1)\n",
    "\n",
    "bo_records = np.array([[y_all[i].item() for i in bo_record] for bo_record in bo_records])\n",
    "bo_records_mean = bo_records.mean(axis=0)\n",
    "bo_records_std = bo_records.std(axis=0)\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "\n",
    "plt.plot(x_axis, bo_records_mean)\n",
    "plt.fill_between(x_axis, bo_records_mean-bo_records_std, bo_records_mean+bo_records_std, alpha=0.4)\n",
    "\n",
    "plt.xlabel(\"Number of molecules queried\")\n",
    "plt.ylabel(\"Top-1 relative growth\")\n",
    "plt.ylim(0, 1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac81272a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"outputs/cnp_bo_records.pkl\", \"wb\") as output_file:\n",
    "    pickle.dump(bo_records, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b5fd57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
