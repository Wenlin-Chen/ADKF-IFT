{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c583b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[12:18:06] Enabling RDKit 2019.09.3 jupyter extensions\n",
      "RDKit WARNING: [12:18:06] Enabling RDKit 2019.09.3 jupyter extensions\n",
      "/scratches/gauss/wc337/miniconda3/envs/par2/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/scratches/gauss/wc337/miniconda3/envs/par2/lib/python3.8/site-packages/learn2learn/vision/benchmarks/omniglot_benchmark.py:7: DeprecationWarning: LANCZOS is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.LANCZOS instead.\n",
      "  from PIL.Image import LANCZOS\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pyprojroot import here as project_root\n",
    "\n",
    "sys.path.insert(0, str(project_root()))\n",
    "\n",
    "from fs_mol.data.dkt import get_dkt_batcher\n",
    "from fs_mol.utils.torch_utils import torchify\n",
    "\n",
    "from bayes_opt.bo_utils import load_covid_moonshot_dataset, run_gp_ei_bo, min_so_far, task_to_batches, PARModelFeatureExtractor\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b7123ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratches/gauss/wc337/miniconda3/envs/par2/lib/python3.8/site-packages/rdkit/Chem/EState/EState.py:48: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  Is = numpy.zeros(nAtoms, numpy.float)\n",
      "/scratches/gauss/wc337/miniconda3/envs/par2/lib/python3.8/site-packages/rdkit/Chem/Graphs.py:43: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  res = numpy.zeros(nAtoms + 1, numpy.float)\n",
      "/scratches/gauss/wc337/miniconda3/envs/par2/lib/python3.8/site-packages/rdkit/Chem/EState/EState_VSA.py:75: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  ans = numpy.zeros(len(bins) + 1, numpy.float)\n"
     ]
    }
   ],
   "source": [
    "task = load_covid_moonshot_dataset(\"covid-moonshot-dataset.csv\", \"../../fs_mol/preprocessing/utils/helper_files/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ac1070b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batcher = get_dkt_batcher(max_num_graphs=100)\n",
    "dkt_batches = torchify(\n",
    "    task_to_batches(task, batcher), \n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a342b4f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PARModelFeatureExtractor(\n",
       "  (graph_feature_extractor): GraphFeatureExtractor(\n",
       "    (init_node_proj): Linear(in_features=32, out_features=128, bias=False)\n",
       "    (gnn): GNN(\n",
       "      (gnn_blocks): ModuleList(\n",
       "        (0): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (6): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (7): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (8): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (9): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (readout): CombinedGraphReadout(\n",
       "      (_weighted_mean_pooler): MultiHeadWeightedGraphReadout(\n",
       "        (_scoring_module): MLP(\n",
       "          (_layers): Sequential(\n",
       "            (0): Linear(in_features=1408, out_features=768, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=768, out_features=12, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (_transformation_mlp): MLP(\n",
       "          (_layers): Sequential(\n",
       "            (0): Linear(in_features=1408, out_features=768, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (_combination_layer): Linear(in_features=768, out_features=512, bias=False)\n",
       "      )\n",
       "      (_weighted_sum_pooler): MultiHeadWeightedGraphReadout(\n",
       "        (_scoring_module): MLP(\n",
       "          (_layers): Sequential(\n",
       "            (0): Linear(in_features=1408, out_features=768, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=768, out_features=12, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (_transformation_mlp): MLP(\n",
       "          (_layers): Sequential(\n",
       "            (0): Linear(in_features=1408, out_features=768, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (_combination_layer): Linear(in_features=768, out_features=512, bias=False)\n",
       "      )\n",
       "      (_max_pooler): UnweightedGraphReadout(\n",
       "        (_combination_layer): Linear(in_features=1408, out_features=512, bias=False)\n",
       "      )\n",
       "      (_combination_layer): Linear(in_features=1536, out_features=512, bias=False)\n",
       "    )\n",
       "  )\n",
       "  (enc_fc): Sequential(\n",
       "    (0): Linear(in_features=2560, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=300, bias=True)\n",
       "  )\n",
       "  (encode_projection): ContextMLP(\n",
       "    (attn_layer): Attention(\n",
       "      (qkv): Linear(in_features=300, out_features=900, bias=False)\n",
       "      (attn_drop): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (mlp_proj): MLP(\n",
       "      (network): Sequential(\n",
       "        (fc0): Linear(in_features=600, out_features=128, bias=True)\n",
       "        (relu0): LeakyReLU(negative_slope=0.01)\n",
       "        (drop0): Dropout(p=0.1, inplace=False)\n",
       "        (fc1): Linear(in_features=128, out_features=128, bias=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (adapt_relation): TaskAwareRelation(\n",
       "    (predrop1): Dropout(p=0.2, inplace=False)\n",
       "    (edge_layer0): EdgeUpdateNetwork(\n",
       "      (sim_network): Sequential(\n",
       "        (conv0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu0): LeakyReLU(negative_slope=0.01)\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu1): LeakyReLU(negative_slope=0.01)\n",
       "        (conv_out): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (node_layer0): NodeUpdateNetwork(\n",
       "      (network): Sequential(\n",
       "        (conv0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu0): LeakyReLU(negative_slope=0.01)\n",
       "      )\n",
       "    )\n",
       "    (edge_layer1): EdgeUpdateNetwork(\n",
       "      (sim_network): Sequential(\n",
       "        (conv0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu0): LeakyReLU(negative_slope=0.01)\n",
       "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu1): LeakyReLU(negative_slope=0.01)\n",
       "        (conv_out): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "    )\n",
       "    (node_layer1): NodeUpdateNetwork(\n",
       "      (network): Sequential(\n",
       "        (conv0): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (relu0): LeakyReLU(negative_slope=0.01)\n",
       "      )\n",
       "    )\n",
       "    (fc1): Sequential(\n",
       "      (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "      (1): LeakyReLU(negative_slope=0.01)\n",
       "    )\n",
       "    (predrop2): Dropout(p=0.2, inplace=False)\n",
       "    (fc2): Linear(in_features=128, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_weights_file = \"../../outputs/PAR/best_validation.pt\"\n",
    "\n",
    "par_model = PARModelFeatureExtractor.build_from_model_file(\n",
    "    model_weights_file,\n",
    "    device=device\n",
    ").to(device)\n",
    "\n",
    "par_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5206bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "representations = []\n",
    "\n",
    "for features in dkt_batches:\n",
    "    representation = par_model.get_representation(features)\n",
    "    representations.append(representation)\n",
    "    \n",
    "del par_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34d6a02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = task.samples\n",
    "\n",
    "x_all = torch.cat(representations, dim=0)\n",
    "y_all = torch.FloatTensor([float(x.numeric_label) for x in dataset]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7406af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_init_points = 16\n",
    "query_batch_size = 1\n",
    "num_bo_iters = 30\n",
    "kernel_type = \"matern\"\n",
    "init_from = 1200\n",
    "noise_init = 0.01\n",
    "noise_prior = True\n",
    "\n",
    "num_repeats = 20\n",
    "\n",
    "bo_records = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc4efa9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                        | 0/20 [00:00<?, ?it/s]/scratches/gauss/wc337/miniconda3/envs/par2/lib/python3.8/site-packages/gpytorch/lazy/lazy_tensor.py:1811: UserWarning: torch.triangular_solve is deprecated in favor of torch.linalg.solve_triangularand will be removed in a future PyTorch release.\n",
      "torch.linalg.solve_triangular has its arguments reversed and does not return a copy of one of the inputs.\n",
      "X = torch.triangular_solve(B, A).solution\n",
      "should be replaced with\n",
      "X = torch.linalg.solve_triangular(A, B). (Triggered internally at  /opt/conda/conda-bld/pytorch_1646755853042/work/aten/src/ATen/native/BatchLinearAlgebra.cpp:1672.)\n",
      "  Linv = torch.triangular_solve(Eye, L, upper=False).solution\n",
      " 95%|        | 19/20 [33:25<01:45, 105.86s/it]"
     ]
    }
   ],
   "source": [
    "for repeat in tqdm(range(num_repeats)):\n",
    "    bo_record = run_gp_ei_bo(dataset, x_all, y_all, num_init_points, query_batch_size, num_bo_iters, kernel_type, device, init_from, noise_init, noise_prior)\n",
    "    bo_records.append(min_so_far(bo_record))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4752fcaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_axis = np.arange(query_batch_size*num_bo_iters+1)\n",
    "\n",
    "bo_records = np.array([[float(-1.0 * y_all[i].item()) for i in bo_record] for bo_record in bo_records])\n",
    "bo_records_mean = bo_records.mean(axis=0)\n",
    "bo_records_std = bo_records.std(axis=0)\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "\n",
    "plt.plot(x_axis, bo_records_mean)\n",
    "plt.fill_between(x_axis, bo_records_mean-bo_records_std, bo_records_mean+bo_records_std, alpha=0.4)\n",
    "\n",
    "plt.xlabel(\"Number of molecules queried\")\n",
    "plt.ylabel(\"Top-1 pIC50 Fluorescence\")\n",
    "plt.ylim(3.5, 9.0)\n",
    "plt.axhline(8.5738)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac81272a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"outputs/par_bo_records.pkl\", \"wb\") as output_file:\n",
    "    pickle.dump(bo_records, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a98afdbb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
