{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c583b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pyprojroot import here as project_root\n",
    "\n",
    "sys.path.insert(0, str(project_root()))\n",
    "\n",
    "from fs_mol.data.cnp import get_cnp_batcher\n",
    "from fs_mol.utils.torch_utils import torchify\n",
    "\n",
    "from bayes_opt.bo_utils import load_cep_dataset, run_gp_ei_bo, min_so_far, task_to_batches, CNPModelFeatureExtractor\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b7123ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = load_cep_dataset(\"cep-dataset-subsampled.csv\", \"../../fs_mol/preprocessing/utils/helper_files/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ac1070b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batcher = get_cnp_batcher(max_num_graphs=100)\n",
    "cnp_batches = torchify(\n",
    "    task_to_batches(task, batcher), \n",
    "    device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a342b4f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNPModelFeatureExtractor(\n",
       "  (graph_feature_extractor): GraphFeatureExtractor(\n",
       "    (init_node_proj): Linear(in_features=32, out_features=128, bias=False)\n",
       "    (gnn): GNN(\n",
       "      (gnn_blocks): ModuleList(\n",
       "        (0): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (1): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (2): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (3): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (4): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (5): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (6): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (7): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (8): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "        (9): GNNBlock(\n",
       "          (mp_layers): ModuleList(\n",
       "            (0): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): RelationalMultiAggrMP(\n",
       "              (message_fns): ModuleList(\n",
       "                (0): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (1): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "                (2): MLP(\n",
       "                  (_layers): Sequential(\n",
       "                    (0): Linear(in_features=64, out_features=192, bias=True)\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (msg_out_projection): Linear(in_features=3072, out_features=128, bias=True)\n",
       "          (mp_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (boom_layer): BOOMLayer(\n",
       "            (linear1): Linear(in_features=128, out_features=1024, bias=True)\n",
       "            (activation): LeakyReLU(negative_slope=0.01)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "            (linear2): Linear(in_features=1024, out_features=128, bias=True)\n",
       "          )\n",
       "          (boom_norm_layer): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout_layer): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (readout): CombinedGraphReadout(\n",
       "      (_weighted_mean_pooler): MultiHeadWeightedGraphReadout(\n",
       "        (_scoring_module): MLP(\n",
       "          (_layers): Sequential(\n",
       "            (0): Linear(in_features=1408, out_features=768, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=768, out_features=12, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (_transformation_mlp): MLP(\n",
       "          (_layers): Sequential(\n",
       "            (0): Linear(in_features=1408, out_features=768, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (_combination_layer): Linear(in_features=768, out_features=512, bias=False)\n",
       "      )\n",
       "      (_weighted_sum_pooler): MultiHeadWeightedGraphReadout(\n",
       "        (_scoring_module): MLP(\n",
       "          (_layers): Sequential(\n",
       "            (0): Linear(in_features=1408, out_features=768, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=768, out_features=12, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (_transformation_mlp): MLP(\n",
       "          (_layers): Sequential(\n",
       "            (0): Linear(in_features=1408, out_features=768, bias=True)\n",
       "            (1): ReLU()\n",
       "            (2): Linear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (_combination_layer): Linear(in_features=768, out_features=512, bias=False)\n",
       "      )\n",
       "      (_max_pooler): UnweightedGraphReadout(\n",
       "        (_combination_layer): Linear(in_features=1408, out_features=512, bias=False)\n",
       "      )\n",
       "      (_combination_layer): Linear(in_features=1536, out_features=512, bias=False)\n",
       "    )\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=2560, out_features=1024, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  )\n",
       "  (encoder_label_fc): Sequential(\n",
       "    (0): Linear(in_features=1, out_features=64, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "  )\n",
       "  (encoder_final_fc): Sequential(\n",
       "    (0): Linear(in_features=576, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=512, out_features=512, bias=True)\n",
       "  )\n",
       "  (decoder_fc): Sequential(\n",
       "    (0): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=256, out_features=256, bias=True)\n",
       "    (7): ReLU()\n",
       "    (8): Linear(in_features=256, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_weights_file = \"../../outputs/FSMol_CNPModel_gnn+ecfp+fc_2022-04-11_16-46-27/best_validation.pt\" #2048\n",
    "\n",
    "cnp_model = CNPModelFeatureExtractor.build_from_model_file(\n",
    "    model_weights_file,\n",
    "    device=device\n",
    ").to(device)\n",
    "\n",
    "cnp_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5206bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "representations = []\n",
    "\n",
    "for features in cnp_batches:\n",
    "    representation = cnp_model.get_representation(features)\n",
    "    representations.append(representation)\n",
    "    \n",
    "del cnp_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34d6a02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = task.samples\n",
    "\n",
    "x_all = torch.cat(representations, dim=0)\n",
    "y_all = torch.FloatTensor([float(x.numeric_label) for x in dataset]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7406af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_init_points = 16\n",
    "query_batch_size = 1\n",
    "num_bo_iters = 40\n",
    "kernel_type = \"matern\"\n",
    "init_from = 1200\n",
    "noise_init = 0.01\n",
    "noise_prior = True\n",
    "\n",
    "num_repeats = 20\n",
    "\n",
    "bo_records = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fc4efa9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 20/20 [46:09<00:00, 138.47s/it]\n"
     ]
    }
   ],
   "source": [
    "for repeat in tqdm(range(num_repeats)):\n",
    "    bo_record = run_gp_ei_bo(dataset, x_all, y_all, num_init_points, query_batch_size, num_bo_iters, kernel_type, device, init_from, noise_init, noise_prior)\n",
    "    bo_records.append(min_so_far(bo_record))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4752fcaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 12.0)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_axis = np.arange(query_batch_size*num_bo_iters+1)\n",
    "\n",
    "bo_records = np.array([[float(-1.0 * y_all[i].item()) for i in bo_record] for bo_record in bo_records])\n",
    "bo_records_mean = bo_records.mean(axis=0)\n",
    "bo_records_std = bo_records.std(axis=0)\n",
    "\n",
    "plt.figure(figsize=(5,5))\n",
    "\n",
    "plt.plot(x_axis, bo_records_mean)\n",
    "plt.fill_between(x_axis, bo_records_mean-bo_records_std, bo_records_mean+bo_records_std, alpha=0.4)\n",
    "\n",
    "plt.xlabel(\"Number of molecules queried\")\n",
    "plt.ylabel(\"Top-1 power conversion efficiency\")\n",
    "plt.ylim(0.0, 12.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac81272a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"outputs/cnp_bo_records.pkl\", \"wb\") as output_file:\n",
    "    pickle.dump(bo_records, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83896349",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
